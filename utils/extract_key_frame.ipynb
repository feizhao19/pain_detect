{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7d7c5e",
   "metadata": {},
   "source": [
    "##### Check the subjects of the clips and extract the key frames of each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38859f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "import moviepy\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from timeit import default_timer as timer\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import argrelextrema\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2f151",
   "metadata": {},
   "source": [
    "###### clips info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f299aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_dir = \"../data/USF/clips/\" # your clip folders\n",
    "clip_dir_nopain = clip_dir + \"no_pain/\"\n",
    "clip_dir_pain = clip_dir + \"pain/\"\n",
    "print(os.path.isdir(clip_dir_nopain), os.path.isdir(clip_dir_pain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad20be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain all the files\n",
    "no_pain_files =[clip_dir_nopain + i for i in os.listdir(clip_dir_nopain)]\n",
    "pain_files = [clip_dir_pain + i for i in os.listdir(clip_dir_pain)]\n",
    "print(\"number of no pain files:{}, and that of pain files:{}\".format(len(no_pain_files), len(pain_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520d1bd",
   "metadata": {},
   "source": [
    "###### Get the  number of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pain_subjects =[]\n",
    "pain_subjects = []\n",
    "for item in no_pain_files:\n",
    "    no_pain_subjects.append(item.split('_')[-2])\n",
    "print(\"num of no pain subjects: {}\".format(len(set(no_pain_subjects))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15242b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in pain_files:\n",
    "    pain_subjects.append(item.split('_')[-2])\n",
    "print(\"num of pain subjects: {}\".format(len(set(pain_subjects))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1133b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pain_subjects = set(no_pain_subjects)\n",
    "pain_subjects = set(pain_subjects)\n",
    "print(no_pain_subjects, pain_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354cbe5",
   "metadata": {},
   "source": [
    "###### check the clip files  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec5ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in no_pain_files:\n",
    "    if not os.path.isfile(item):\n",
    "        print(\"the file does exist:{}\".format(item))\n",
    "for item in pain_files:\n",
    "    if not os.path.isfile(item):\n",
    "        print(\"the file does exist:{}\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae24551",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of no pain files:{}, and that of pain files:{}\".format(len(no_pain_files), len(pain_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bdd297",
   "metadata": {},
   "source": [
    "###### Extract the frames based on local maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x, window_len=13, window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "    import numpy as np    \n",
    "    t = np.linspace(-2,2,0.1)\n",
    "    x = np.sin(t)+np.random.randn(len(t))*0.1\n",
    "    y = smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string   \n",
    "    \"\"\"\n",
    "#     print(len(x), window_len)\n",
    "#     if x.ndim != 1:\n",
    "#         raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n",
    "\n",
    "#     if x.size < window_len:\n",
    "#         raise ValueError, \"Input vector needs to be bigger than window size.\"\n",
    "\n",
    "#     if window_len < 3:\n",
    "#         return x\n",
    "\n",
    "#     if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "#         raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "\n",
    "    s = np.r_[2 * x[0] - x[window_len:1:-1],\n",
    "              x, 2 * x[-1] - x[-1:-window_len:-1]]\n",
    "    #print(len(s))\n",
    "\n",
    "    if window == 'flat':  # moving average\n",
    "        w = np.ones(window_len, 'd')\n",
    "    else:\n",
    "        w = getattr(np, window)(window_len)\n",
    "    y = np.convolve(w / w.sum(), s, mode='same')\n",
    "    return y[window_len - 1:-window_len + 1]\n",
    "\n",
    "#Class to hold information about each frame\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, id, frame, value):\n",
    "        self.id = id\n",
    "        self.frame = frame\n",
    "        self.value = value\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if self.id == other.id:\n",
    "            return self.id < other.id\n",
    "        return self.id < other.id\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return other.__lt__(self)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id and self.id == other.id\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "def rel_change(a, b):\n",
    "    x = (b - a) / max(a, b)\n",
    "    print(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca441e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.executable)\n",
    "#Setting fixed threshold criteria\n",
    "USE_THRESH = False\n",
    "#fixed threshold value\n",
    "THRESH = 0.6\n",
    "#Setting fixed threshold criteria\n",
    "USE_TOP_ORDER = False\n",
    "#Setting local maxima criteria\n",
    "USE_LOCAL_MAXIMA = True\n",
    "#Number of top sorted frames\n",
    "NUM_TOP_FRAMES = 20\n",
    "len_window = 80\n",
    "#Video path of the source file\n",
    "# videopath = video_path\n",
    "#Directory to store the processed frames\n",
    "dir = \"../data/USF/temple2/\"\n",
    "#smoothing window size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_keyframes(videopath, output_dir):\n",
    "\n",
    "#     print(\"Video :\" + videopath)\n",
    "#     print(\"Frame Directory: \" + output_dir)\n",
    "    video_name = videopath.split('/')[-1].split('.')[0]\n",
    "\n",
    "    cap = cv2.VideoCapture(str(videopath))\n",
    "\n",
    "\n",
    "    curr_frame = None\n",
    "    prev_frame = None\n",
    "\n",
    "    frame_diffs = []\n",
    "    frames = []\n",
    "    ret, frame = cap.read()\n",
    "    i = 1\n",
    "\n",
    "    while(ret):\n",
    "        luv = cv2.cvtColor(frame, cv2.COLOR_BGR2LUV)\n",
    "        curr_frame = luv\n",
    "        if curr_frame is not None and prev_frame is not None:\n",
    "            #logic here\n",
    "            diff = cv2.absdiff(curr_frame, prev_frame)\n",
    "            count = np.sum(diff)\n",
    "            frame_diffs.append(count)\n",
    "            frame = Frame(i, frame, count)\n",
    "            frames.append(frame)\n",
    "        prev_frame = curr_frame\n",
    "        i = i + 1\n",
    "        ret, frame = cap.read()\n",
    "    \"\"\"\n",
    "        cv2.imshow('frame',luv)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \"\"\"\n",
    "    cap.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    if USE_TOP_ORDER:\n",
    "        # sort the list in descending order\n",
    "        frames.sort(key=operator.attrgetter(\"value\"), reverse=True)\n",
    "        for keyframe in frames[:NUM_TOP_FRAMES]:\n",
    "            name = \"frame_\" + str(keyframe.id) + \".jpg\"\n",
    "            cv2.imwrite(output_dir + \"/\" + name, keyframe.frame)\n",
    "\n",
    "    if USE_THRESH:\n",
    "        print(\"Using Threshold\")\n",
    "        for i in range(1, len(frames)):\n",
    "            if (rel_change(np.float(frames[i - 1].value), np.float(frames[i].value)) >= THRESH):\n",
    "                #print(\"prev_frame:\"+str(frames[i-1].value)+\"  curr_frame:\"+str(frames[i].value))\n",
    "                name = \"frame_\" + str(frames[i].id) + \".jpg\"\n",
    "                cv2.imwrite(output_dir + \"/\" + name, frames[i].frame)\n",
    "\n",
    "\n",
    "    if USE_LOCAL_MAXIMA:\n",
    "#         print(\"Using Local Maxima\")\n",
    "        diff_array = np.array(frame_diffs)\n",
    "        sm_diff_array = smooth(diff_array, len_window)\n",
    "        frame_indexes = np.asarray(argrelextrema(sm_diff_array, np.greater))[0]\n",
    "        if \"sub053_pro1\" in item:\n",
    "            print(\"find sub53\")\n",
    "            for i in frame_indexes:\n",
    "                name = \"frame_\" + str(frames[i - 1].id) + video_name + \".jpg\"\n",
    "                #print(dir+name)\n",
    "                cv2.imwrite(output_dir + name, cv2.rotate(frames[i - 1].frame,cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "        else:\n",
    "#             print(\"not find sub53\")\n",
    "            for i in frame_indexes:\n",
    "                name = \"frame_\" + str(frames[i - 1].id) + video_name + \".jpg\"\n",
    "                #print(dir+name)\n",
    "                cv2.imwrite(output_dir + name, cv2.rotate(frames[i - 1].frame,cv2.ROTATE_90_CLOCKWISE))\n",
    "\n",
    "#     plt.figure(figsize=(40, 20))\n",
    "#     plt.locator_params(numticks=100)\n",
    "#     plt.stem(sm_diff_array)\n",
    "#     plt.savefig(dir + 'plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create keyframe folder\n",
    "%mkdir \"../data/USF/keyframe/\"\n",
    "%mkdir \"../data/USF/keyframe/pain\"\n",
    "%mkdir \"../data/USF/keyframe/no_pain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pain_frames = \"../data/USF/keyframe/no_pain/\"\n",
    "pain_frames = \"../data/USF/keyframe/pain/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6233665",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(pain_files):\n",
    "    capture_keyframes(item, pain_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c09941",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(no_pain_files):\n",
    "    capture_keyframes(item, no_pain_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b20199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yoloclone]",
   "language": "python",
   "name": "conda-env-.conda-yoloclone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
